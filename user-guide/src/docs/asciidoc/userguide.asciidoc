
// ADOC Settings:
:experimental:
:reproducible:
:icons: font
:listing-caption: Listing
:sectnums:
:toc:
:toclevels: 5
:xrefstyle: short
:title-logo-image: junit-utils.png

ifdef::backend-pdf[]
:pdf-themesdir: {docdir}

:source-highlighter: rouge
//:rouge-style: github
endif::[]

//shortcuts
:source-highlighter: rouge
:spec-testing-image: SpecDrivenOrderer.png

:folder-main: ../../main
:folder-test: ../../test
:samples-package: lu/mms/common/quality/userguide
// main
:sample-models: {folder-main}/java/{samples-package}/models
// test
:examples: {folder-test}/java/{samples-package}
:asset-springcontext-test: {folder-test}/java/{samples-package}/spring/context

// DOC Start here
= JUnit Utils User Guide
v{artifactoryVersion}, {localdate}
:organization: MMS
:doctype: book

[abstract]
Abstract

JUnit Utils aim as a set of good practices and tools, is to simplify software developers approach when it comes
to planning, designing, and writing unit tests. The present user guide dive into the proposed features and solution, and
provide the documentation for users and developers.

There are already a lot of frameworks providing an impressive added value to software testing, like JUnit, Mockito,
Hamcrest, Awaitility and many others. Nevertheless, writing tests is sometimes painful for many reasons. You surely
faced the desire to modify your production class to make it more 'testable', or even skip (leave it for integration
tests) a peace of code because preparing the testcase for it could/will be time consuming.

The _JUnit Utils_ brings few additional tools, to ease and simplify the unit tests design and implementation
approach, and therefore be gratified by a cleanest and more readable code, an impressive code coverage score, and last
but not least, prevent a large amount of bugs to occur.
{nbsp} +
{nbsp} +
{nbsp} +
{nbsp} +
{nbsp} +
{nbsp} +
{nbsp} +
{nbsp} +
{nbsp} +
{nbsp} +
{nbsp} +
{nbsp} +
[quote, Burt Rutan, Retired American aerospace engineer and entrepreneur]
____
_Testing leads to failure, and failure leads to understanding._
____


== Installation

=== pom.xml
The journey trip with _JUnit Utils_ start by including it in your project _pom.xml_ file.

.JUnit Utils dependency
[source, xml]
----
<dependency>
    <groupId>lu.mms.common</groupId>
    <artifactId>junit-utils</artifactId>
    <version>${junit-utils.version}</version>
    <scope>test</scope>
</dependency>
----

.Keep up to date
TIP: The _JUnit Utils_ latest version is: [*{artifactoryVersion}*]

It is also important to note that this version requires *Java 11* to work.

Having this done, we do not need anything else to enjoy unit testing our code.

=== Maven Dependencies
The following dependencies are ready to be used as soon as _JUnit Utils_ has been installed:

. org.mybatis.mybatis
. org.apache.commons
** commons-text
** commons-lang3
. commons-io
. logback-classic
. org.reflections
. spring-boot-starter-test
. hamcrest
. mockito
** mockito-junit-jupiter
** mockito-core
. H2
. awaitility
. apiguardian-api
. JUnit 5
** junit-jupiter
** junit-platform:
*** junit-platform-runner
*** junit-platform-engine
*** junit-platform-commons
*** junit-platform-launcher


== Framework tour

=== Configuration Parameters
While using _JUnit Utils_ library, you might need to modify some default behavior. You simply have to create a file
named _junit-utils.XXX_, where _XXX_ stands for the configuration file type. It could be a *YAML* file or a
*properties* file.
example of valid configuration file names:

- junit-utils.yaml
- junit-utils.yml
- junit-utils.properties

For those you prefer to keep the JUnit configuration together, it is possible to use the JUnit platform configuration
to store the _JUnit Utils_ configuration in the file named _junit-platform.properties_. The table below lists the
configuration entries.

._JUnit Utils_ properties
[cols="30%, 60%, 10%",frame=topbot,grid=rows]
|===
|Property |Description |Default value

m|component-scan|The package that will be scanned by the framework|
m|log-reflections|ON/OFF the reflections logging| true
m|show-banner|Shows the library banner| true
m|fancy-banner|Shows the fancy banner if 'show-banner' = true and 'fancy-banner' = true|true
|===

.Example of yaml configuration
[source, yaml]
----
junit-utils:
  component-scan:   lu.mms
  log-reflections:  false
  show-banner:      true
----

.Example of .properties configuration
[source, properties]
----
junit-utils.show-banner=true
junit-utils.fancy-banner=false
----



=== Extensions API
One of the major improvement brought by _JUnit 5_ is its extension model. Such extension give us the possibility to
customise the test execution. A couple of extension are being proposed by _JUnit Utils_
for that purpose.

==== ReturnsMocksExtension
Unit testing a class implies to mock a lot of classes around. Some of the mocked classes are often declared in the
unit test in order to controller their behavior (with stubbers), and we expect from those classes the keep having the
same behavior in the text context.

Let set the following context:

.Testcase context
[source, java, linenums, indent=0]
----
include::{sample-models}/Customer.java[tag=entity]

include::{sample-models}/Identity.java[tag=entity]

include::{sample-models}/Report.java[tag=entity]
----

When unit testing the _CustomerManager_ let say we would like to check that the _CustomerManager_ return the right ID for
a given customer, and that the correct method is fired in _Identity_. Doing this require a lot of operation to be done:
*(1)* mock _Identity_,  *(2)* stub to _getId()_ so that it returns the expected ID, *(3)* mock _Customer_ and
*(4)* stub _getIdentity()_ to return _IdentityMock_.

.Unit test straight approach
[source, java, linenums, indent=0]
----
include::{examples}/mock/MockExample1Test.java[tag=example]
----

Please note that the more behaviors to stub and cases to verify, the more we will have to repeat the _init()_ section in
our example. So lets try to automatise this initialization process. To do this, let us: *(1)* comment the stub
_when(customerMock.getIdentity()).thenReturn(identityMock);_, *(2)* configure _customerMock_ to return mocks
(see line 14), and *(3)* and run the test again.

a bit surprised ... the test failed.

This is because the returned mock (by _customerMock_) is not the same as the one we
declared in the our test. Just modify the asserts to confirm this state as you can see in the bellow listing.

.Simplifying the testcase initialization step: attempt #1
[source, java, linenums, indent=0]
----
include::{examples}/mock/MockExample2Test.java[tag=example]
----

Assuming we are declaring a mock in our test class, we would like to interact with that mock all over the test run, and
verify his behavior if needed. It comes to us that in the context of this JUNit 5 custom extension, to have a unique
mock instance in the testcase context.

Fortunately, *@ReturnsMocksExtension* helps to resolve this anomaly and returns the mock declared in our test, so that
any predefined behavior or stub applies to the test case. We just need to extend our class with
the *ReturnsMocksExtension*:

.ReturnsMocksExtension installation
[source, java, linenums, indent=0]
----
@ExtendWith(ReturnsMocksExtension.class)
class MockExample3Test {
    // ...
}
----

Of course, to keep the code readable and let the developer focus in the test case, lets get rid of this initialization
phase, which can grow up really fast with the classes to mock and behaviors to stub, and add the *MockitoExtension* as
well.

.Simplifying the testcase initialization step: attempt #2
[source, java, linenums, indent=0]
----
include::{examples}/mock/MockExample4Test.java[tag=example]
----

As you already noted, the example *#4* if much more elegant and simple to read, understand and maintain than example *#1*.
We can easily focus on the purpose of the test, by removing the noisy code. Of course, this example is really
simplified but as soon as the code grows up, the proposed approach is really helpful.
{nbsp} +
{nbsp} +

==== MockInjectionExtension
When coding, it happens that we have to deal with beans which shares one or more common interfaces, or simply, extends
the same base classes. Testing then is naturally simple, but we have to put some effort on declaring/creating the
related mocks, prepare the collection and inject them personally ensure that they will be injected in the correct
field, which some chance for the field to be renamed for example.

The _MockInjectionExtension_ will help a lot here by doing it for us, and again, help us to keep the noisy code out of
what we should focus on. It is also important to notice that this extension will inject the mocks & spies declared by
the user in the test class instance. Last but not least, the subject under test is instantiated via appropriate
constructor, setter and even lookup methods ('@Autowired' method) with the corresponding mocks as arguments.
By mocks here, we understand the ones declared by the user in the test class, otherwise a new mock instance will be
created.

.MockInjectionExtension & mock/spy injection.
[source, java, linenums, indent=0]
----
include::{examples}/mock/MockInjectionExtensionTest.java[tag=example]
----

==== ReinforceMockExtension
This extension is purely technical. It helps to avoid NPE when lifecycle methods are executed, and some method
members were not mocked at all or simply injected. This extension will scan the test instance, recover the properties
annotated with @Mock, and inject the empty fields with the declared mocks when relevant.

.ReinforceMockExtension in action.
[source, java, linenums, indent=0]
----
include::{examples}/reinforcement/ReinforceMockExtensionExampleTest.java[tag=example]
----

==== MockitoSpyExtension
As many developers, we try our best to test solitary unit as the require less work in test preparation. Most of the
border classes are mocked and we are just dealing with the behaviors we have prepared. But not all unit testers use
solitary tests. It is some times  required to define sociable units, and indeed without focusing on the neighboring
classed we try to reproduce the way the unit behave in production environment. A solution to do so is ito use the spies,
and of course, they are not fully initialised.

This is where the _MockitoSpyExtension_ will help by injecting the declared test class mocks and spies if possible.
As any other JUnit 5 extension, we just need to register the extension for the tests class spy to be initialized with
relevant mock and spies.

.MockitoSpyExtension in action
[source,java,linenums,indent=0]
----
@ExtendWith(MockitoSpyExtension.class)
class MockitoSpyExtensionExampleTest {
    @Spy
    private House houseSpy;

    @Mock
    private Room roomMock;

    // ...
}
----
In the above listing the 'roomMock' will be injected in the 'houseSpy', if of course, there is a such field (with) the
same type in the 'House' class.
{nbsp} +
{nbsp} +

==== BeanLifeCycleExtension
This extension make it possible to test the bean life cycle method. One of the coolest annotation we use to use when
coding is the _@PostConstruct_/_@PreDestroy_ annotations. As per  the _@PostConstruct_ javadoc for example, a
method annotated with this annotation should be invoked before the class is put into service, and therefore, before
the class is being also tested. In integration test for example we do not have so much to do, as it is usually properly
executed after dependency injection. Let set the following testcase context.

.Testcase context
[source, java, linenums, indent=0]
----
include::{sample-models}/lifecycle/Identity.java[tag=entity]
----

Unit testing this class will required to run the _init()_ method, if we want to reproduce its full behavior like in
production context. Lets give a try.

.PostConstruct Initialization: attempt #1
[source, java, linenums, indent=0]
----
include::{examples}/lifecycle/BeanLifeCycleExtensionExample1Test.java[tag=example]
----

As in the previous section example, we need to remember to aware of all the _@PostConstruct_ methods, and execute via
reflection feature to init the testcase, or even worse, make the _@PostConstruct_ method available for other class
in the production code, just because are struggling to access it in the unit test. Moreover, renaming the
_@PostConstruct_ method implies aligning the test as well.

With the _BeanLifeCycleExtension_, we automatise this process, remove the noisy initialization part of the test case,
and ensure that the test case will be modified only when the logic in the production class change, with optimized
effort for code maintenance and code review. The improved unit test looks like this:

.PostConstruct Initialization: attempt #2
[source, java, linenums, indent=0]
----
include::{examples}/lifecycle/BeanLifeCycleExtensionExample2Test.java[tag=example]
----

We can notice that the noisy code just disappeared, and the developer can focus on the behaviors to test.

==== MocksContextParameterResolver
This is a helper extension, as its name states, it is a paramter provider, which goal is to provide the mocks context
to the test instance method. Any debugging and mocks context check is therefore possible to verify the value using
during the test case initiatization.

==== MyBatisSqlSessionResolver
This extension make it possible to resolve useful beans, which provides methods to interact directly with SQL session
and the DataSource.

.Beans provided by _MyBatisSqlSessionResolver_
[cols="40%, 60%",frame=topbot,grid=rows]
|===
|Beans |Description

m|SqlSessionFactory|The MyBatis SQL session Factory
m|SqlSession|The MyBatis Sql Session
m|JdbcTemplate|The JDBC Template (spring-jdbc)
|===

==== MyBatisMapperExtension
(see annotation _@MyBatisMapperTest_)

==== DisableTestMethodOnFailureExtension
This extension make it possible to skip up coming tests as soon a test method within a test class fails.
In the example bellow, the execution _givenCandidateIsEntryLevel()_ pass, then comes the _whenTheTestCaseFails()_ which
fails. In this case, there is no need to execute the third method (_thenDoNotExecuteAnyOtherTestCase()_), which is
ignored thanks the usage of our extension.

.Disabling test methods in case of failure
[source, java, linenums, indent=0]
----
include::{examples}/conditions/DisableTestMethodOnFailureExampleTest.java[tag=example]
----

=== Basic Annotations
As designed, annotation make it easy to add a given behavior to and object or a class. This is why annotations have been
a good candidate to ease developer life when it comes to software testing. _JUnit Utils_ comes with couples of
annotations to achieve that goal.

==== _@MockValue_
When coding most of the time with properties values, referring to them via the _@Value_ annotation, we need extra steps
in the test case settings, like inject value to the annotated fields. Some times, the annotated field is modified
 after code reviews or simple code refactoring. This implies to comeback to the test and align it as well.

With the *_@MockValue_* annotation, we automatise this process and initialise the subject under test
(_@InjectMock_ annotated) properties. We will focus on the following context in the upcoming examples.

.Testcase context
[source, java, linenums, indent=0]
----
include::{sample-models}/mockvalue/Identity.java[tag=entity]
----

To unit this class, we usually have to *(1)* modified the production code by adding a setter, or *(2)* within the
testcase, inject a value to the _id_ variable.

.Injecting a value to the _@Value_ field.
[source, java, linenums, indent=0]
----
include::{examples}/mockvalue/MockValueExample1Test.java[tag=example]
----

This operation look quit simple, but lets think about any change in the production code, as shown in
_MockValueExample1Test_ listing. This implies to align the test with the code, and more code to review for the
colleagues. This unit test can be improved using the *@MockValue* (and *MockValueExtension*). Please take a look at
the reworked previous unit test case.

.MockValue and MockValueExtension in action.
[source, java, linenums, indent=0]
----
include::{examples}/mockvalue/MockValueExample2Test.java[tag=example]
----

One of the coolest functionality brought by *_@MockValue_* and its extension, is the benefit of the @Value defaulting.
It simply work in a last move wins mode. That means:

1. First we consider the code defaulting
2. Then the test case defaulting
3. and then if an explicit value is set to the property then it is the one which will be considered (injected).

.Context: @Mock with defaulting.
[source, java, linenums, indent=0]
----
include::{examples}/mockvalue/MockValueExample7Test.java[tag=example_context]
----

.MockValue defaulting example.
[source, java, linenums, indent=0]
----
include::{examples}/mockvalue/MockValueExample7Test.java[tag=example]
----

.Mockito inclusion
NOTE: You probably noted we have included Mockito _@InjectMocks_ in the unit test. The benefit is to have the subject
under test initialized before any other operation, and the custom extension will look for the field annotated with
_@InjectMocks_ and inject the desired values.

.Extension Registration order
[CAUTION]
As per JUnit 5 user guide, the extensions registered via _@ExtendWith_ will be executed in the order in
which they are declared in the source code. So be aware of the interaction between extensions when using them together.

Please find the properties provided by _@MockValue_ in the next table.

._@MockValue_ properties
[cols="22%, 60%, 18%",frame=topbot,grid=rows]
|===
|Property |Description |Default value

m|value|An array of values to look for in the subject under test|
m|testcase|The test method where to apply the value|
|===

===== # value
The value is an array of String, that's define that should be initialized. Lets say we have the following entity:

.Class with multiple properties annotated with _@value_.
[source, java, linenums, indent=0]
----
include::{sample-models}/mockvalue/Customer.java[tag=entity]
----

When unit testing this class, we would like to initialize all the annotated properties with default value. With the
traditional way, we need to set each property (via reflection for example). With _@MockValue#value_ we simply declare
all the target fields as show bellow.

.@MockValue#value in action.
[source, java, linenums, indent=0]
----
include::{examples}/mockvalue/MockValueExample3Test.java[tag=example]
----

===== # testcase
Some times we want to initialize the values for some test cases and not the other. We can achieve this with
_@MockValue#testcase_ as follows:

.@MockValue#testcase in action.
[source, java, linenums, indent=0]
----
include::{examples}/mockvalue/MockValueExample4Test.java[tag=example]
----

==== _@MyBatisMapperTest_
One part of application development is oriented as well in data retrieval and manipulation from database. Mybatis
mappers is being used for this purpose in many projects and as other part of the code, need to be tested.
It is possible to apply the configuration manually, but ... of course to save the time we need to test and maintain the
production code, this task has been automatized and standardized with the _@MyBatisMapperTest_ annotation (and the relevant
extension _MyBatisMapperExtension_, which registered by default by _@MyBatisMapperTest__).

.@MyBatisMapperTest at method level.
[source, java, linenums, indent=0]
----
include::{examples}/mybatis/MyBatisMapperTestExample1Test.java[tag=method_level_example]
----
.Full test class example
NOTE: see full class in: _MyBatisMapperTestExample1Test.java_

.@MyBatisMapperTest at class level.
[source, java, linenums, indent=0]
----
include::{examples}/mybatis/MyBatisMapperTestExample2Test.java[tag=class_level_example]
----

Please find the properties provided by _@MyBatisMapperTest_ in the next table.
{nbsp} +
{nbsp} +
{nbsp} +
{nbsp} +
{nbsp} +
._@MyBatisMapperTest_ properties
[cols="22%, 60%, 18%",frame=topbot,grid=rows]
|===
|Property |Description |Default value

m|script|The SQL scripts to run when configuring the DataSource|
m|testIsolation|Manage the connection to the database. If `true` the database connection will be closed after each
test method|`true`
|===

==== _@InjectMapper_
As you probable noticed in previous example (_MyBatisMapperTestExample2Test_), the subject under test is _@InjectMapper_
annotated. In fact, initializing MyBatis context is not enough, we still need to retrieve the target mapper we want to
test. This is where _MyBatisMapperExtension_ come into the game and inject the target mapper in the field annotated with
_@InjectMapper_.

==== _@SpringContextRunner_

When the project we are involved in grows up, with many modules and classes, the project configuration as a critical
should keep under control to avoid tricky issues.

Spring provide the _AbstractApplicationContextRunner_ which is very well suited for configuration test. However, when
using directly it, we face some minor issue like:

1. trouble to add a mock in the context
2. copy/paste the code in case of multiple testcase
3. not easy maintenance of the test afterwards

JUnit Utils provide the annotation _@SpringContextRunner_ to solve the points listed above and helps by way to keep
the testcase readable. Please find a use case of the _@SpringContextRunner_ usage (together with the related extension
_SpringContextRunnerExtension.class_).

.Testing with SpringContextRunner
[source, java, linenums, indent=0]
----
include::{examples}/spring/context/SpringContextRunnerExample1Test.java[tag=example]
----

You can denote here how easy it is to add a mock in the context.
Please find the properties provided by _@SpringContextRunner_ in the next table.

._@SpringContextRunner_ properties
[cols="25%, 57%, 18%",frame=topbot,grid=rows]
|===
|Property |Description |Default value

m|withActiveProfiles|Set the active spring profiles|
m|withAllowBeanDefinitionOverriding|Allow bean definition overriding|true
m|withPropertyValues|Add the specified Environment property pairs|
m|withSystemProperties|Add the specified System property pairs|
m|withPropertySource|Apply the specified Property source|
m|withConfiguration|Register the specified configuration class with the ApplicationContext|NoClass.class
m|withUserConfiguration|Register the specified user configuration classes with the ApplicationContext|
m|withBeans|Register the specified user beans with the ApplicationContext|
m|withMocks|Register the specified classes as mocks with the ApplicationContext|
m|injectDeclaredMocks|Register the mocks & spies declared in the test class|true
m|mappersPackage|Mock the mappers under given packages|
|===

There another point where _@SpringContextRunner_ will be very interesting for us. In fact, when it comes to mock
something and/or declare a mock, we need to insert it again the the context. Now with the _@SpringContextRunner_ we just
need to declare the mock in the test for it to be injected in the context, as shown below:

.Friendly mocks in _@SpringContextRunner_
[source, java, linenums, indent=0]
----
include::{examples}/spring/context/SpringContextRunnerExample1Test.java[tag=example]
----

==== _@Fixture_
This is a class and field level annotation, that's enable _JUnit Utils_ with powerful fixture files. As you may
already know, a fixture is a standalone unit or functionality of a project. It is usually best practice, when testing that
before deriving the test scripts, we should determine the fixture to be tested. Such a fixture usually contains a list
of steps, which, combined in a given sequence, give a test case.

In context of _JUnit Utils_, the fixture file contains the atomic steps that can be applied to prepare a test
case execution. Please take a look of an example of fixture file.

.An example of _@Fixture_ file.
[source, java, linenums, indent=0]
----
include::{examples}/fixture/FixtureFileExample.java[tag=example]
----

Having already defined our fixture file, can therefore use it in our unit test as show below.

._@Fixture_ file in action.
[source, java, linenums, indent=0]
----
include::{examples}/fixture/FixtureExample1Test.java[tag=example]
----

As you already noticed, we are free of initializing the fixture file by injecting the mocks from our test class. Indeed,
the mocks (and spies) declared in the test class are injected in the fixture, if the relevant field hasn't yet been
initialized. Doing so help to keep cleaner and readable test and the developer can focus on the functionality to test.

The table below shows _@Fixture_ annotation the properties.

._@Fixture_ properties
[cols="18%, 64%, 18%",frame=topbot,grid=rows]
|===
|Property |Description |Default value

m|injectMocks|Inject test class (test case) mocks to the class with _@Fixture_ or not|`true`
|===

==== _@ExtendWithTestUtils_

Having all the previous features up and running, some behaviour has been defaulted to simplify unit test design, plan,
implementation and configuration. The _@ExtendWithTestUtils_ annotation, in addition to emphasizing the fact our test is a unit
test, is setting in the main time de most common default behavior by registering the following extension (in order):

- MockitoExtension
- ReturnsMocksExtension
--  _[#1] ensure the created mock will return the test instance declared @Mock/@Spy_
- MockValueExtension
--  _[#2] initialize the @Value (via @MockValue) when relevant_
- ReinforceMockExtension
--  _[#3] enrich the declared mocks to avoid NPE on lifecycle methods call_
- MockitoSpyExtension
--  _[#4] enrich the @Spy fields with the previous (#1 and #2) knowledge_
- MockInjectionExtension
--  _[#5] ensure the SUT (@InjectMocks) is properly initialized ..._
- FixtureExtension
- MocksContextParameterResolver

Please find the properties provided by _@ExtendWithTestUtils_ in the next table.

._@ExtendWithTestUtils_ properties
[cols="22%, 60%, 18%",frame=topbot,grid=rows]
|===
|Property |Description |Default value

m|returnMocks|Answer (_Mockito.Answers_) with mocks defined in user test (see: _ReturnsMocksExtension_)|`true`
m|initMocks|The MockitoSettings strictness|`true`
m|initSpies|The flag to init mockito spies (@Spy) with test case mock and spies if relevant|`true`
m|reinforceMock|The flag to enable/disable the mock reinforcement|`true`
|===

.Testing with @ExtendWithTestUtils
[source, java, linenums, indent=0]
----
include::{examples}/testutils/ExtendWithTestUtilsExample1Test.java[tag=example]
----

==== _@WithBeanLifeCycle_

This annotation extends the test class with _BeanLifeCycleExtension_, which allows to execute and test the subject
under test life cycle if relevant. The _@WithBeanLifeCycle_ annotation makes also possible to decide whether to
execute the life cycle method at JUnit5 '@BeforeEach' stage or '@BeforeTestExecution' stage), via its
_beforeEach_ property.

._@WithBeanLifeCycle_ properties
[cols="22%, 60%, 18%",frame=topbot,grid=rows]
|===
|Property |Description |Default value

m|_beforeEach_|The flag to switch lifecycle methods execution between '@BeforeEach' stage or '@BeforeTestExecution' stage|`false`
|===

=== Other delicacies

==== DataSourceMockBuilder
This builder has been introduced to provide a ready to go mocked DataSource. Up to the developer to declare and inject
it in the test context, the spring context or event to use it directly in the test class.

.Mocked DataSource as a Bean
[source, java, linenums, indent=0]
----
@Configuration
class DataSourceMockExample1Test {
    @Bean
    @Primary
    public DataSource dataSource() {
        return DataSourceMockBuilder.newDataSourceMock("oracle").build();
    }
}
----

.Verifying the mocked DataSource properties
[source, java, linenums, indent=0]
----
include::{examples}/db/DataSourceMockExample1Test.java[tag=example]
----

==== DB Reverse Engineering
One of the most interesting moment when testing our code, is the time when we really feel like we are ready to submit
'production' like data to the developed feature. The easiest way to achieve this is to collect the target database
extract, throw everything in '.sql' file, call it all when setting up our datasource and that's it.
It could be interesting to gather only the data related to the target test case, in with case we will be able to
assert more efficiently the target DML (insert/update/delete). The proposed DB Reverse Engineering could accelerate and
ease the data retrieval and analysis, and even make it possible to have the proper migration script for each test case.

.Extracting the test case context
[source, java, linenums, indent=0]
----
include::{examples}/db/re/ReverseEngineeringWizardExample1Test.java[tag=example]
----

Example of DDL generated at the [ReverseEngineeringWizardExample1Test] line 37, will look like the following one:
[source, sql, linenums, indent=0]
----
CREATE SCHEMA IF NOT EXISTS SCHEMA_NAME;

DROP TABLE SCHEMA_NAME.CUSTOMER IF EXISTS; --null

CREATE TABLE SCHEMA_NAME.CUSTOMER (
	ID_CUST VARCHAR2(5) PRIMARY KEY
,	CD_TYPE VARCHAR2(3) NOT NULL
,	CD_LANGUE VARCHAR2(2)
,	LI_NAME VARCHAR2(20) NOT NULL
,	LI_SURNAME VARCHAR2(30)
,	LI_COMMENT VARCHAR2(600)
,	CONSTRAINT CHK_CUSTOMER CHECK (
        CD_LANGUE IN ('FR', 'NL', 'EN', 'DE') and CD_TYPE IN ('AXE', 'PPT')
    )
);
----

And here is an example of DML generated at the [ReverseEngineeringWizardExample1Test] line 38:
[source, sql, linenums, indent=0]
----
DELETE FROM  SCHEMA_NAME.CUSTOMER;

INSERT INTO SCHEMA_NAME.CUSTOMER (
	(ID_CUST, CD_TYPE, CD_LANGUE, LI_NAME, LI_SURNAME, LI_COMMENT)
VALUES
	(8356, 'AXE', 'FR', 'FITZGERALD', 'MATTEW', null)
;
----

Following the DDL and DML generation, it is possible to persist then to .sql (in the `test/resources` file using the
method `Ddl.createFile` and  `Dml.createFile` like presented in [ReverseEngineeringWizardExample1Test] line
42. Please notice that a class provided (line 38) so that the target migration script (.sql file) will be created in the same package
 as the provided class. Otherwise, the .sql file is created in the '/sql' folder.

=== Specification Testing

==== ScenarioTesting
The `ScenarioNameGenerator` is a custom Test Method name generator, which turn how the test class simple name, and the
test method name as well into a human readable name. In addition, each class is considered as a scenario
(a 'Scenario: ' key word is added to the result class mapped name). This functionality is handling the snake case
method as well.

.Examples
[cols="10%, 45%, 45%",frame=topbot,grid=rows]
|===
|type |To map |Result

m|class|UserNameGeneratorTest.class|Scenario: User name generator test
m|method|shouldMapNameWhenDefaultName|Should map name when default name
m|method|should_map_name_when_snake_case_name|Should map name when snake case name
|===

.Example of use of ScenarioTesting
[source, java, linenums, indent=0]
----
include::{examples}/bdd/ScenarioTestingExampleTest.java[tag=example]
----

==== EnumArgument
This is an annotation that allows to repeat a test scenario execution with a set of provided data, and is to be
used together with the ´ScenarioTesting´ abstract class.

.EnumArgument properties
[cols="10%, 90%,frame=topbot,grid=rows]
|===
|Property |Description

m|value|Enum class to be used (enums constants) during test scenario execution
m|include|The enum constants name subset, to be included during the test scenario execution
m|exclude|The enum constants name subset, to be excluded during the test scenario execution
|===

.Example of use of EnumArgument
[source, java, linenums, indent=0]
----
include::{examples}/bdd/EnumArgumentExampleTest.java[tag=example]
----

.Example of use of EnumArgument with 'include'
[source, java, linenums, indent=0]
----
include::{examples}/bdd/EnumArgumentIncludeExampleTest.java[tag=example]
----

.Example of use of EnumArgument with 'exclude'
[source, java, linenums, indent=0]
----
include::{examples}/bdd/EnumArgumentExcludeExampleTest.java[tag=example]
----

==== ValueArgument
This is an annotation that allows to repeat a test scenario execution with a set of provided values, and is to be
used together with the ´ScenarioTesting´ abstract class. For the moment, only strings can be provided as
'Data Provider', but other arguments sources can be added in the future such as:
 - data files: excels, csv, jValueArgumentson
 - arrays / iterables

.Example of use of ValueArgument with 'strings'
[source, java, linenums, indent=0]
----
include::{examples}/bdd/StringValueArgumentExampleTest.java[tag=example]
----

==== ScenarioTesting
The ´ScenarioTesting´ is an abstract which brings test factory behavior to our test. The test method named with
the behavioral pattern will be ordered in as per 'GIVEN, WHEN, THEN' key words and executed. In case one of the step
fails, the test plan is aborted and the remaining tests method to executed are skipped.

==== SpecificationDrivenOrderer
Usually the feature (or use case) we are implementing are specified and much respect a set of rules. To be sure that our
implementation match with the requirement, we use to implement some use case testing for this purpose.
The `SpecificationDrivenOrderer` method orderer ease this process by order the test method in a GIVEN-WHEN-THEN order.

.Example of test class with _SpecificationDrivenOrderer_ and _ScenarioNameGenerator_
[source, java, linenums, indent=0]
----
include::{examples}/bdd/SpecificationDrivenOrdererExampleTest.java[tag=example]
----

.and the resulting test plan output
image::{spec-testing-image}[]

== Future works
There are still many subject uncovered in the _JUnit Utils_ framework and in this user guide as well, that are in
the area of interest of most of the developers. Including some tools for integration tests are in the bags as well, as integration with tools like _Cucumber_
and _Selenium_, when it comes to integration tests.

== Last thought
The solutions and features presented in this user guide presents a the general approach we adapted to improve the tests
quality. We hope they will be helpful to solve impediment software developer are facing during coding and testing.
In case they do not fit to your project, do not hesitate to contribute with new ideas and propositions.

Happy coding !
